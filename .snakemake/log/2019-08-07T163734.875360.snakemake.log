Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 22
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	StarCollect
	1	all
	2

[Wed Aug  7 16:37:35 2019]
rule StarCollect:
    input: Sample_70160/Sample_70160Log.final.out, Sample_70161/Sample_70161Log.final.out, Sample_70162/Sample_70162Log.final.out
    output: averageMappedLength.txt, input.txt, mappedPercent.txt, percentMultimappers.txt, unmappedTooShort.txt
    jobid: 1

[Wed Aug  7 16:37:35 2019]
Finished job 1.
1 of 2 steps (50%) done

[Wed Aug  7 16:37:35 2019]
localrule all:
    input: Sample_70160/Sample_70160Log.final.out, Sample_70161/Sample_70161Log.final.out, Sample_70162/Sample_70162Log.final.out, Sample_70160/Sample_70160Aligned.sortedByCoord.out.bam, Sample_70161/Sample_70161Aligned.sortedByCoord.out.bam, Sample_70162/Sample_70162Aligned.sortedByCoord.out.bam, averageMappedLength.txt, input.txt, mappedPercent.txt, percentMultimappers.txt, unmappedTooShort.txt
    jobid: 0

[Wed Aug  7 16:37:35 2019]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /home/manninm/pyflow-RNAseq/.snakemake/log/2019-08-07T163734.875360.snakemake.log
